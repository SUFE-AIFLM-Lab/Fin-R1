![Fin-R1标题](title.png)
---
# Fin-R1金融推理大模型：以创新技术重塑金融决策智能

Fin-R1 是一款针对金融领域复杂推理的大型语言模型，由上海财经大学统计与数据科学学院人工智能金融大模型实验室（SUFE-AIFLM-Lab）开发并开源。该模型以 Qwen2.5-7B-Instruct 为基座，通过高质量的可验证金融问题微调训练，最终表现在多个金融领域基准测试上的表现达到参评模型的SOTA水平。



## 目录<a name="toc"></a>
1. [概述](#summary)
2. [数据构建](#data)
3. [微调训练](#trainning)
7. [评测使用方法](#use1)
8. [模型评测结果](#results)
9. [模型使用方法](#use)
10. [未来展望](#todo)
11. [联系我们](#connection)
## 💡 概述<a name="summary"></a>
Fin-R1 是一个金融领域的推理大语言模型，由上海财经大学统计与数据科学学院人工智能金融大模型实验室（SUFE-AIFLM-Lab）开发并开源。该模型以轻量化的7B参数量级设计，在显著降低部署成本的同时，通过构建面向金融推理场景的高质量正确思维链数据与SFT+RL两阶段训练框架，为模型在金融领域的应用中提供坚实的理论支撑、业务规则、决策逻辑以及技术实现能力，提升模型的金融复杂推理能力以用于实现不同的功能：

### +数据-场景总览图

### 模型应用效果展示 
#### 安全合规
![金融计算示例](iamges/合规.gif)
#### 智能风控
![金融计算示例](iamges/风控.gif)
#### 智能投顾
![金融计算示例](iamges/投顾.gif)
#### ESG
![金融计算示例](iamges/ESG.gif)
#### 英文金融
![金融计算示例](iamges/英文金融.gif)
#### 金融计算
![金融计算示例](iamges/金融计算.gif)
#### 金融代码
![金融计算示例](iamges/金融代码.gif)

### 总体工作流程
![总体工作流程](iamges/.frame2_cn.png)

## 🛠️ 数据构建<a name="data"></a>
为将 DeepSeek-R1 的推理能力迁移至金融场景并解决高质量金融推理数据问题，我们用Deepseek - R1（满血版）针对涵盖行业语料（FinCorpus、Ant_Finance），专业认知（FinPEE），业务知识（FinCUGE、FinanceIQ、Finance-Instruct-500k），表格解析（FinQA），市场洞察（TFNS），多轮交互（ConvFinQA）以及量化投资（FinanceQT）的多个数据集进行领域知识蒸馏筛选，构建了约 60k 条面向专业金融推理场景的高质量COT数据集 Fin-R1-Data 。该数据集涵盖中英文金融垂直领域的多维度专业知识，并根据具体任务内容将其分为金融代码、金融专业知识、金融非推理类业务知识和金融推理类业务知识四大模块，可有效支撑银行、基金和证券等多个金融核心场景。本研究构建了基于 Deepseek - R1 的数据蒸馏框架，并创新性提出对思维链进行“答案+推理”双轮质量打分筛选方法，首轮基于规则匹配和Qwen2.5-72B-Instruct模型对答案准确性评分，次轮对推理链的逻辑一致性、术语合规性等推理逻辑进行深度校验以保证数据质量。

### +数据处理图

### 数据蒸馏

在蒸馏过程中，我们严格依照 [DeepSeek - R1](https://github.com/deepseek-ai/DeepSeek-R1) 官方提供的细节，进行相应设置的数据蒸馏操作：

### 数据筛选

对数据生成结果进行了两次筛选，在第一阶段，我们通过仅接受与标准答案相匹配的解决方案来执行数据筛选，在第二阶段，我们对模型的推理轨迹数据进行筛选。每一次筛选都会将数据标注为good或bad进行区分：

1）答案打分：对于蒸馏得到的数据，针对客观题（如选择题、判断题），采用基于规则的匹配方式，校对蒸馏数据的正确性；对于无法通过规则匹配的结果，利用 Qwen2.5-72B-Instruct 模型对模型生成的答案以及正确答案进行打分，正确得 1 分，错误得 0 分。

2）推理过程打分：对于经过上一步筛选得到的正确思维链数据，再次利用 Qwen2.5-72B-Instruct 模型对推理轨迹进行打分，高质量数据得 1 分，低质量数据得 0 分。我们采取了如下几个指标来进行打分：
    1.内部一致性：检查推理过程中的步骤是否一致，并且是否能够逐步逻辑地推导出标准答案。
    2.术语重叠度：检查推理过程中使用的术语与标准答案中的术语的重叠程度。重叠度越高越好。
    3.推理步骤数量：评估推理过程是否包含足够的步骤（至少3步）。
    4.逻辑一致性：确保推理过程中的步骤与标准答案在逻辑上高度一致，并检查是否存在明显的错误或遗漏。
    5.内容多样性：检查推理过程中是否存在大量重复的步骤。
    6.与任务领域的相关性：检查推理过程是否涉及与任务领域相关的内容（任务领域：{task_domain}）。如果推理反映了与任务领域的相关性，则给予更高的评分。
    7.与任务指令的一致性：检查推理过程是否与任务指令高度相关。相关性越高越好。如果推理内容完全符合任务指令，则给予更高的评分。

我们将经过两轮筛选后均标注为good的数据作为高质量的 COT 数据用于 SFT ；而未经过筛选标注为bad的数据则作为推理QA数据用于强化学习（RL）。

### Fin-R1-Data数据分布如下：

|数据集|数据量|
|-------------|--------|
|ConvFinQA-R1-Distill |7629|
|Finance-Instruct-500K-R1-Distill | 11300 |
|FinCUGE-R1-Distill | 2000 |
|FinQA-R1-Distill | 2948 |
|TFNS-R1-Distill | 2451|
|FinanceIQ-R1-Distill | 2596 |
|FinanceQT-R1-Distill | 152 |
|Ant-Finance-R1-Distill | 1548 |
|FinCorpus-R1-Distill | 29288|
|FinPEE-R1-Distill | 179 |
|总计| 60091 |

有关数据的具体任务内容和示例可在[Fin-R1-Data](https://github.com/SUFE-AIFLM-Lab/SuFin-R1/blob/main/Fin-R1-Data.md)查看


## 🚀 微调训练<a name="trainning"></a>

### 两阶段流程
研究针对金融领域复杂推理任务，采用两阶段训练框架优化Qwen-7B-instruct（引用）得到金融推理大语言模型Fin-R1。通过高质量金融推理数据的有监督微调（SFT）和强化学习GRPO（引用）相结合的方式，采用格式奖励和准确度奖励进行强化学习，Fin-R1在金融推理任务中实现了高精度与强泛化能力。
#### 第一阶段----领域知识注入： 

针对通用模型在金融术语理解、合规性判断等任务中存在逻辑断裂与场景泛化不足等问题。团队基于Llama-Factory框架进行微调，对通用基座模型Qwen2.5-7B进行了深度领域适配，注入大量高质量金融推理类COT数据，显著提升模型对金融术语、金融逻辑推理和风险预测的理解能力。 

#### 第二阶段----强化学习优化： 

在模型掌握复杂推理技能后，团队使用Open-R1框架进行强化学习训练，在比较多种强化学习算法效果后选取GRPO（Generalized Reward Policy Optimization）算法以动态奖励机制优化模型输出的专业性与合规性，并采取了一种创新性方法：去除传统的 Reference model ，同时采用格式奖励+准确率奖励双驱动机制来优化模型的学习。

![grpo](grpo.png)


## 🧐 评测使用说明 <a name="use1"></a>

本研究构建了基于金融领域多任务特性的基准测试框架，并选取五类具有代表性的开源异构数据集进行系统性验证，我们主要做了如下修改：

1.在添加我们的评测数据集时，数据集的形式不需要统一，只需在[adapter.py](https://github.com/SUFE-AIFLM-Lab/SuFin-R1/blob/main/adapter.py)中写清楚读取数据规则即可。

2.添加了 LLM as Judger 的方式，我们目前使用 GPT-4o 作为打分模型。若不想使用 LLM as Judger ，可以使用客观题的正则化匹配答案评分方式。

3.修改调用api的方式，可根据情况选择request和openai两种方式（原代码只支持openai方式）。

评估时针对各评估集样本容量异质性问题，设计了动态阈值判定策略：当评估集样本量低于1,000时实施全量测试以保证统计显著性；当样本量超过1,000时，通过分层抽样策略随机抽取1,000个具有类别代表性的样本构成精简评估集。

## 🚨 模型评测结果 <a name="results"></a>
在覆盖金融、数学以及语言能力的权威评测中，参数量仅有7B的Fin-R1都展现出卓越的性能，大幅超越了其他通用LLM。特别是在金融场景中，Fin-R1-7B在FinQA和ConvFinQA上的表现均超过了满血版DeepSeek-R1。

### 金融场景
我们在以下覆盖多项金融业务场景的基准测试上对模型进行评估，最终结果中模型全面超越参评的同规模模型并逼近32B级大模型表现，以75的平均得分位居第二，且在 FinQA 和 ConvFinQA 两大金融问答基准上得分在参评模型中登顶第一。
| Model                        | Parameters | FinQA | ConvFinga | Ant_Finance | TFNS |  Finance-Instruct-500k  | Average |
|------------------------------|------------|-------|-----------|-------------|------|-------------------------|---------|
| DeepSeek-R1                  | unknown    | 71.0  | 82.0      | 90.0        | 78.0 | 70.0                    | 78.2    |
| Qwen-2.5-Instruct            | 32B        | 72.0  | 78.0      | 84.0        | 77.0 | 58.0                    | 73.8    |
| DeepSeek-R1-Distill-Qwen     | 32B        | 70.0  | 72.0      | 87.0        | 79.0 | 54.0                    | 72.4    |
| Qwen2.5-SFT                  | 7B         | 73.0  | 81.0      | 76.0        | 68.0 | 61.0                    | 71.9    |
| Qwen-2.5-Instruct            | 14B        | 68.0  | 77.0      | 84.0        | 72.0 | 56.0                    | 71.4    |
| DeepSeek-R1-Distill-Qwen     | 14B        | 62.0  | 73.0      | 82.0        | 65.0 | 49.0                    | 66.2    |
| Qwen-2.5-Instruct            | 7B         | 60.0  | 66.0      | 85.0        | 68.0 | 49.0                    | 65.6    |
| DeepSeek-R1-Distill-Qwen     | 7B         | 55.0  | 62.0      | 71.0        | 60.0 | 42.0                    | 58.0    |
| Fin-R1                       | 7B         | 76.0  | 85.0      | 81.0        | 71.0 | 62.9                    | 75.2    |


## 💪 模型使用说明 <a name="use"></a>
您可以直接从huggingface中下载我们的模型权重
```
git clone https://huggingface.co/SUFE-AIFLM-Lab/Fin-R1
```
准备好依赖环境，采用如下命令一键安装vllm
```
pip install vllm
```
命令行一键启动模型服务：
```
vllm serve "/path/Fin-R1" --port 8000 --gpu-memory-utilization 0.9 --max-model-len 16384 --tensor-parallel-size 2 --served-model-name "Fin-R1"
```


## 📌 声明及未来展望 <a name="todo"></a>
SuFin-R1作为金融领域的推理型大语言模型，虽能出色完成诸多金融任务，为用户提供专业服务，但现阶段仍存在技术瓶颈与应用限制。它提供的建议和分析结果仅供参考，不可等同于专业金融分析师或专家的精准判断。我们诚挚希望用户以批判性思维审视模型输出，结合自身专业知识与经验进行决策。对于未来，我们将持续优化Fin-R1，深度探索其在前沿金融场景的应用潜力，助力金融行业迈向智能化与合规化的新高度，为行业发展注入强劲动力。


## 📫 联系我们 <a name="connection"></a>
诚邀业界同仁共同探索AI与金融深度融合的创新范式，共建智慧金融新生态。
