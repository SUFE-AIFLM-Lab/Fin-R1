![SuFin-R1标题](title.png)
---
# SuFin-R1金融推理大模型：以创新技术重塑金融决策智能

SuFin-R1 是一款针对金融领域复杂推理的大型语言模型，由上海财经大学统计与数据科学学院人工智能金融大模型实验室（SUFE-AIFLM-Lab）开发并开源。该模型以 Qwen2.5-7B 为基座，通过高质量的可验证金融问题微调训练，最终表现在多个金融领域基准测试上的表现达到SOTA水平。

![评测结果](.frame1_cn.png)

## 目录<a name="toc"></a>
1. [概述](#summary)
2. [金融推理数据](#data)
3. [模型微调训练](#trainning)
7. [模型评测系统](#result)
8. [模型评测结果](#results)
9. [未来展望](#todo)
10. [联系我们](#connection)
## 💡 概述<a name="summary"></a>
SuFin-R1 是一个金融领域的推理大语言模型，通过构建面向金融推理场景的高质量正确思维链数据，强化模型对金融推理逻辑的精准捕捉，解决传统方法中思维链噪声问题，然后采用SFT预热阶段和优化的GRPO强化学习阶段的两阶段训练框架为模型在金融领域的应用中提供坚实的理论支撑、业务规则、决策逻辑以及技术实现能力，提升模型的金融复杂推理能力以用于实现不同的功能：

###应用场景示例: 安全合规 信用评估 智能投顾 

[![视频封面](https://img.shields.io/badge/点击播放-视频演示-blue)](https://github.com/SUFE-AIFLM-Lab/SuFin-R1/blob/main/%E9%A3%8E%E6%8E%A7.mp4)

示例
<video controls width="800">
  <source src="https://github.com/SUFE-AIFLM-Lab/SuFin-R1/blob/main/%E9%A3%8E%E6%8E%A7.mp4">
  您的浏览器不支持 HTML5 视频。
</video>


### 总体工作流程
![总体工作流程](.frame2_cn.png)

## 🛠️ 数据处理<a name="data"></a>
为将 DeepSeek-R1 的推理能力迁移至金融场景并解决传统金融数据分布散、标注成本高以及缺乏对复杂推理逻辑针对性设计的问题，我们基于 Ant_Finance、FinanceIQ、FinanceQT、ConvFinQA、TFNS、Finance-Instruct、FinPEE、FinCorpus、FinCUGE 这九大数据集，通过双轮动态蒸馏构建了约 30k 条面向专业金融推理场景的高质量COT数据集 FinR1-Data 。该数据集由 Deepseek-R1（完整版）提炼而成，并创新性对思维链进行“答案+推理”双轮质量打分筛选，涵盖中英文金融垂直领域的多维度专业知识，并根据具体任务内容将其分为金融代码、金融专业知识、金融非推理类业务知识和金融推理类业务知识四大模块。
### 数据蒸馏

在蒸馏过程中，我们严格依照 [DeepSeek - R1](https://github.com/deepseek-ai/DeepSeek-R1) 官方提供的细节，进行相应设置的数据蒸馏操作：

### 数据筛选

对数据生成结果进行了两次筛选：

1）答案打分：对于蒸馏得到的数据，针对客观题（如选择题、判断题），采用基于规则的匹配方式，校对蒸馏数据的正确性；对于无法通过规则匹配的结果，利用 Qwen2.5-72B-Instruct 模型对模型生成的答案以及正确答案进行打分，正确得 1 分，错误得 0 分。

2）推理过程打分：对于经过上一步筛选得到的正确思维链数据，再次利用 Qwen2.5-72B-Instruct 模型对推理轨迹进行打分，高质量数据得 1 分，低质量数据得 0 分。我们采取了如下几个指标来进行打分：
```
    1.内部一致性：检查推理过程中的步骤是否一致，并且是否能够逐步逻辑地推导出标准答案。
    2.术语重叠度：检查推理过程中使用的术语与标准答案中的术语的重叠程度。重叠度越高越好。
    3.推理步骤数量：评估推理过程是否包含足够的步骤（至少3步）。
    4.逻辑一致性：确保推理过程中的步骤与标准答案在逻辑上高度一致，并检查是否存在明显的错误或遗漏。
    5.内容多样性：检查推理过程中是否存在大量重复的步骤。
    6.与任务领域的相关性：检查推理过程是否涉及与任务领域相关的内容（任务领域：{task_domain}）。如果推理反映了与任务领域的相关性，则给予更高的评分。
    7.与任务指令的一致性：检查推理过程是否与任务指令高度相关。相关性越高越好。如果推理内容完全符合任务指令，则给予更高的评分。
```
我们将经过两轮筛选后得到的数据作为高质量的 COT 数据用于 SFT ；而未经过筛选的数据则用于强化学习（RL）。

### FinR1-Data数据分布如下：

|数据集|数据量|
|-------------|--------|
|Convfinqa published|3814|
|Finance instruct published | 5650 |
|FinCUGE Instruction published | 2,000 |
|FinQA published | 1,474 |
|TFNS published | 1,225|
|FinanceIQ published | 1,038 |
|Quant Trading Instruct published | 60 |
|Ant Finance published | 619 |
|FinCorpus published | 14,636|
|FinPEE published | 179 |
|总计| 30695 |

有关数据的具体任务内容和示例可在[FinR1-Data](https://github.com/SUFE-AIFLM-Lab/SuFin-R1/blob/main/Financial-R1-Distill-Data.md)查看

## 🚀 训练流程<a name="trainning"></a>

### 训练流程

#### 第一阶段----领域知识注入： 

针对通用模型在金融术语理解、合规性判断等任务中存在逻辑断裂与场景泛化不足等问题。团队基于Llama-Factory框架进行微调，对通用基座模型Qwen2.5-7B进行了深度领域适配，注入大量高质量金融推理类COT数据，显著提升模型对金融术语、金融逻辑推理和风险预测的理解能力。 

#### 第二阶段----强化学习优化： 

在模型掌握复杂推理技能后，团队使用Open-R1框架进行强化学习训练，在比较多种强化学习算法效果后选取GRPO（Generalized Reward Policy Optimization）算法以动态奖励机制优化模型输出的专业性与合规性，并采取了一种创新性方法：去除传统的 Reference model ，同时采用格式奖励+准确率奖励双驱动机制来优化模型的学习。

![grpo](grpo.png)


## 🧐 模型评测系统 <a name="result"></a>

我们基于 evalscope 框架进行评测，详细使用方法可以参考官方使用手册 [evalscope](https://github.com/modelscope/evalscope)。我们主要做了如下修改：

1.在 evalscope/benchmark/ 中添加了我们的评测数据集，数据集的形式不需要统一，只需在[adapter.py](https://github.com/SUFE-AIFLM-Lab/SuFin-R1/blob/main/adapter.py)中写清楚读取数据规则即可。

2.添加了 llm as judger 的方式，我们目前使用 gpt-4o 作为打分模型。若不想使用 llm as judger ，可以使用客观题的正则化匹配答案评分方式。

3.修改调用api的方式，可根据情况选择request和openai两种方式（原代码只支持openai方式）。



## 🚨 模型评测结果 <a name="results"></a>
在覆盖金融、数学以及语言能力的权威评测中，参数量仅有7B的SuFin-R1都展现出卓越的性能，大幅超越了其他通用LLM。特别是在金融场景中，SuFin-R1-7B在FinQA和ConvFinQA上的表现均超过了满血版DeepSeek-R1。

##结果表格重做

### 金融场景
我们在以下金融场景的基准测试上对模型进行评估，这些基准测试聚焦真实世界中金融表格数据驱动的数值推理任务以及多轮交互场景。模型在 FinQA 和 ConvFinQA 两大金融问答基准上，性能表现超越了满血版 DeepSeek-R1 ，展现出模型对上下文连贯性与数值推理一致性的强大处理能力。
| Model                            | FinQA   | ConvFinga | Ant_Finance | TFNS    | Finance-Instruct |
|---------------------------------|---------|-----------|-------------|---------|------------------|
| FinR1-7B                        | 0.761   | 0.84      | 0.81        | 0.718   | 0.629            |
| Qwen-2.5-7B-Instruct            | 0.60    | 0.66      | 0.85        | 0.68    | 0.49             |
| Qwen-2.5-32B-Instruct           | 0.72    | 0.78      | 0.84        | 0.77    | 0.58             |
| DeepSeek-R1                     | 0.71    | 0.82      | 0.90        | 0.78    | 0.70             |
| DeepSeek-R1-Distil I-Qwen-32B   | 0.70    | 0.72      | 0.87        | 0.79    | 0.54             |
| DeepSeek-R1-Distil I-Qwen-7B    | 0.55    | 0.62      | 0.71        | 0.60    | 0.42             |
| DeepSeek-R1-Distil I-Qwen-14B   | 0.62    | 0.73      | 0.82        | 0.65    | 0.49             |

### 数学能力评估
我们的实验发现虽然没有特意提升模型的数学能力，但是经过金融推理训练后的模型在数学场景中也表现出一定性能的提升。
| 模型                     | MATH-500 (EM) | AIME 2024 (Pass@1) |
|--------------------------|---------------|--------------------|
| FinR1-7B                 | 76.4          | 20                 |
| GPT4o-0513               | 74.6          | 9.3                |
| LLama3.1-405B            | 73.8          | 23.3               |
| claude3.5-sonnet 1022    | 78.3          | 16                 |
| Step-2-16K             | 77.6          | 10                 |
| GLM-4-Plus             | 74.8          | 3.3                |

中文场景专精化：SuFin-R1 在 CEval 上以 78.04 的突破性表现超越 GPT-4o ，彰显本土化优势，配合 73.74 的英文指令跟随能力（ifeval），构建起横跨中英的金融服务智能体基础。

### 中文能力

| 模型                     | CEval    |
|--------------------------|----------|
| FinR1-7B                 | 78.04    |
| GPT4o-0513               | 76       |
| LLama3.1-405B            | 61.5     |
| claude3.5-sonnet 1022    | 76.7     |
| XuanYuan2-70B          | 72.7     |

### 英文指令跟随场景

| 模型                     | ifeval   |
|--------------------------|----------|
| o1-mini-2024-09-12     | 75.4     |
| FinR1-7B                 | 73.74    |
| Llama3.1-8B-Instruct   | 73.4     |
| Gemma-2-9B-it          | 72.5     |
| Qwen2.5-7B-Instruct    | 72.7     |
| GLM-4-9B-Chat          | 69.3     |
| Phi-4                  | 64       |

## 推理和部署

## 📌 声明及未来展望 <a name="todo"></a>
SuFin-R1作为金融领域的推理型大语言模型，虽能出色完成诸多金融任务，为用户提供专业服务，但现阶段仍存在技术瓶颈与应用限制。它提供的建议和分析结果仅供参考，不可等同于专业金融分析师或专家的精准判断。我们诚挚希望用户以批判性思维审视模型输出，结合自身专业知识与经验进行决策。对于未来，我们将持续优化SuFin-R1，深度探索其在前沿金融场景的应用潜力，助力金融行业迈向智能化与合规化的新高度，为行业发展注入强劲动力。
## 📫 联系我们 <a name="connection"></a>
诚邀业界同仁共同探索AI与金融深度融合的创新范式，共建智慧金融新生态。
